#pip install langgraph langchain langchain_openai langchain_google_genai tavily-python langchain_community "httpx==0.27.2"

import operator
import json
from typing import Annotated, List, Tuple, Union, Literal, Optional
from typing_extensions import TypedDict

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph, END, START

import os
from dotenv import load_dotenv
import openai
from langchain_community.tools.tavily_search import TavilySearchResults #ë­ì²´ì¸ë„êµ¬


# 0. ì„¤ì • ë¡œë“œ # .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (KPI í‰ê°€ìš© ë“±)
openai_client = openai.Client(api_key=os.getenv("OPENAI_API_KEY"))

# 1. ë„êµ¬ ë° LLM ì„¤ì •

# Tavily ë„êµ¬ ì„¤ì • (API Key í™˜ê²½ë³€ìˆ˜ í™•ì¸)
# LangChain ë„êµ¬ë“¤ì€ ë³´í†µ os.environì— í‚¤ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì¸ì‹í•¨.
# ëª…ì‹œì ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì‘ì„±.
if not os.getenv("TAVILY_API_KEY"):
    raise ValueError("Tavily API Keyê°€ ì—†ìŠµë‹ˆë‹¤!")

tavily_tool = TavilySearchResults(max_results=5)
tools = [tavily_tool]

# LLM ì„¤ì • ì¶”ì²œ ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ Plannerì™€ Replannerì—ëŠ” ê³ ì„±ëŠ¥ ëª¨ë¸(GPT-4o) ê¶Œì¥
llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)
# llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)

# Agent Executor ì„¤ì • #ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ê°„ë‹¨í•œ Agent (íŠœí† ë¦¬ì–¼ì˜ execute_stepì—ì„œ ì‚¬ìš©)
agent_executor = create_react_agent(llm, tools)

# ---------------------------------------------------------
# 2. State ì •ì˜ (ì…ë ¥ ë°ì´í„°ë¥¼ ì €ì¥í•  êµ¬ì¡°)
# ---------------------------------------------------------
class PlanExecute(TypedDict):
    input: str                         # ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ (ë˜ëŠ” í¬ë§·íŒ…ëœ ë¬¸ìì—´)
    user_context: dict                 # location, decibel_level, user_goal, current_time
    user_preference: dict              # preferred_genres, preferred_artists
    plan: List[str]                    # ì‹¤í–‰ ê³„íš
    past_steps: Annotated[List[Tuple], operator.add] # ìˆ˜í–‰í•œ ì‘ì—… ê¸°ë¡
    response: str                      # ìµœì¢… JSON ì‘ë‹µ

# 3. ë°ì´í„° ëª¨ë¸ (Pydantic) ì •ì˜
class Plan(BaseModel):
    """ê²€ìƒ‰ ê³„íš"""
    steps: List[str] = Field(description="ê²€ìƒ‰ ë‹¨ê³„")

# class Response(BaseModel):
#     """ìµœì¢… ì‚¬ìš©ì ì‘ë‹µ"""
#     response: str = Field(description="ìµœì¢… ì¶”ì²œ ê²°ê³¼ (ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¥¼ ê²ƒ)")

class Act(BaseModel):
    """
    Replannerì˜ íŒë‹¨ ê²°ê³¼:
    - ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ response í•„ë“œì— ìµœì¢… JSONì„ ë‹´ìŒ
    - ë¶€ì¡±í•˜ë©´ plan í•„ë“œì— ì¶”ê°€ ê³„íšì„ ë‹´ìŒ
    responseì™€ plan ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì±„ì›Œì ¸ì•¼ í•¨
    """

    # Response classë‘ ê²¹ì¹¨
    response: Optional[str] = Field(
        default=None,
        description="ìµœì¢… JSON ì‘ë‹µ (ì •ë³´ê°€ ì¶©ë¶„í•  ë•Œ ì‘ì„±í•˜ëŠ” í•„ë“œ)"
    )
    plan: Optional[List[str]] = Field(
        default=None,
        description="ì¶”ê°€ ê³„íš (ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì‘ì„±í•˜ëŠ” í•„ë“œ)"
    )

# ---------------------------------------------------------
# 4. Prompts ì„¤ì • (Taxonomy & Output Format ë°˜ì˜)
# ---------------------------------------------------------

# (1) ì´ˆê¸° ê³„íš ìˆ˜ë¦½ í”„ë¡¬í”„íŠ¸
planner_prompt = ChatPromptTemplate.from_messages([
    ("system",
     """ë‹¹ì‹ ì€ ìŒì•… ì¶”ì²œì„ ìœ„í•œ 'ê²€ìƒ‰ ê³„íšê°€(Search Planner)'ì…ë‹ˆë‹¤.
     ì‚¬ìš©ìì˜ ìƒí™©(Context)ê³¼ ì·¨í–¥(Preference)ì„ ë¶„ì„í•˜ì—¬, Tavilyë¡œ ê²€ìƒ‰í•  êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ìš°ì„¸ìš”.

     ### [í•µì‹¬ ê·œì¹™]
     1. ë³µí•© ì¿¼ë¦¬ ìƒì„±: ë°˜ë“œì‹œ 'Context(ì¥ì†Œ/ëª©í‘œ)'ì™€ 'Genre'ë¥¼ ê²°í•©í•˜ì—¬ ê²€ìƒ‰ì–´ë¥¼ ë§Œë“œì„¸ìš”.
        - (X) Bad: "Metallica ë…¸ë˜ ê²€ìƒ‰"
        - (O) Good: "**ë„ì„œê´€ì—ì„œ ë“£ê¸° ì¢‹ì€** Metallicaì˜ **ì–´ì¿ ìŠ¤í‹± ì»¤ë²„ ê³¡** ê²€ìƒ‰"
     2. Taxonomy ì°¸ê³ : ì•„ë˜ì˜ 'ì¥ì†Œ(Location)'ì™€ 'ëª©í‘œ(Goal)' ë¶„ë¥˜ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”.
        - Location: cafe, library, co-working, moving, gym, home, park
        - Goal: focus, relax, sleep, active, anger, consolation, neutral
     """),
    ("user", "Context: {user_context}\nPreference: {user_preference}\nRequest: {input}")
])

first_planner = planner_prompt | llm.with_structured_output(Plan)

# (2) Replanner (ê²€í†  ë° ë‹µë³€ ìƒì„±) í”„ë¡¬í”„íŠ¸ 
replanner_system_prompt = replanner_system_prompt = """
ë‹¹ì‹ ì€ 'ìƒí™© ë§¥ë½ ì¸ì‹ ìŒì•… ì¶”ì²œ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ì™€ ì‚¬ìš©ì ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ìŒì•…ì„ ì¶”ì²œí•˜ê³ , ë¶„ì„ìš© ë°ì´í„°ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.

### 1. Taxonomy & Logic Matrix (ê¸°ì¤€í‘œ)
ì¶”ì²œ ë¡œì§ì€ ì•„ë˜ì˜ ì •ì˜ë¥¼ ì—„ê²©íˆ ë”°ë¦…ë‹ˆë‹¤.

(1-1) Goal (ëª©í‘œ) â†’ Audio Features ê¸°ë³¸ ë²”ìœ„
- Focus / Sleep: 
  - Energy: 0.0 ~ 0.4 (ë‚®ìŒ) | Tempo: 60 ~ 90 BPM | Inst: 0.7 ~ 1.0 (ê°€ì‚¬ ì§€ì–‘)
- Relax / Consolation: 
  - Acousticness: 0.6 ~ 1.0 | Valence: 0.3 ~ 0.6 (ì°¨ë¶„í•¨)
- Active / Anger: 
  - Energy: 0.7 ~ 1.0 (ë†’ìŒ) | Tempo: 120+ BPM | Valence: 0.6+ (ê°•ë ¬í•¨)
  
(1-2) Goal (ëª©í‘œ) â†’ Recommended Genres (ê°€ì´ë“œë¼ì¸)
ëª©í‘œì— ë”°ë¼ ì•„ë˜ ì¥ë¥´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê³ ë ¤í•˜ë˜, ì‚¬ìš©ì ì„ í˜¸(Preference)ê°€ ìˆë‹¤ë©´ ìœ ì—°í•˜ê²Œ ì¡°ì •í•˜ì‹­ì‹œì˜¤.

- Focus / Sleep:
  - [Classical, Ambient, Lo-fi, Piano, Soundtrack, New-age]
  - (Note: ê°€ì‚¬ê°€ ì—†ê³  ì°¨ë¶„í•œ ì¥ë¥´ ìœ„ì£¼)

- Relax / Consolation: 
  - [Acoustic, Ballad, R-nb, Jazz, Indie, Folk]
  - (Note: ê°ì„±ì ì´ê³  ë¶€ë“œëŸ¬ìš´ ì¥ë¥´ ìœ„ì£¼)

- Active / Anger: 
  - [Pop, K-Pop, Rock, Hip-hop, Electronic]
  - (Note: ë¹„íŠ¸ê°€ ê°•í•˜ê³  ì—ë„ˆì§€ê°€ ë†’ì€ ì¥ë¥´ ìœ„ì£¼)

(2) Location (ì¥ì†Œ) â†’ Vibe & Instrumentalness
- Strict (Library, Co-working): 
  - ê°€ì‚¬ ë°©í•´ ê¸ˆì§€ (Inst: 0.8~1.0). Vibe: `calm`, `melancholy`.
- Casual (Cafe, Home, Park): 
  - í—ˆë°/ì ë‹¹í•œ ê°€ì‚¬ í—ˆìš©. Vibe: `groovy`, `uplifting`, `dreamy`.
- Active (Gym, Moving): 
  - ë¦¬ë“¬ê° í•„ìˆ˜. Vibe: `intense`, `groovy`.

(3) Decibel (ì†ŒìŒ) â†’ Energy Fine-tuning
- Silent/Quiet: ë²”ìœ„ ë‚´ ìµœì†Ÿê°’ ì„¤ì • (ë¶„ìœ„ê¸° ìœ ì§€).
- Loud/Very Loud: ë²”ìœ„ ë‚´ ìµœëŒ“ê°’ ì„¤ì • (ì†ŒìŒ ë§ˆìŠ¤í‚¹).

---

### 2. Reasoning Steps (ìƒê°ì˜ ìˆœì„œ)
ê°’ì„ ê²°ì •í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì•„ë˜ 3ë‹¨ê³„ë¥¼ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.

1. Step 1 (Goal): ìœ„ 'Logic Matrix'ë¥¼ ì°¸ê³ í•˜ì—¬ `Genre`ì™€ `target_audio_features`ì˜ ê¸°ë³¸ ë²”ìœ„ë¥¼ ì¡ìœ¼ì‹­ì‹œì˜¤.
2. Step 2 (Location): ì¥ì†Œì˜ ì‚¬íšŒì  ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ `Vibe`ì™€ `Instrumentalness`ë¥¼ êµ¬ì²´í™”í•˜ì‹­ì‹œì˜¤.
3. Step 3 (Decibel): ì†ŒìŒë„ë¥¼ ê³ ë ¤í•˜ì—¬ `Energy` ìˆ˜ì¹˜ë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ì‹­ì‹œì˜¤. (ì ˆëŒ€ ê¸°ë³¸ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ë§ ê²ƒ)

---

### 3. Primary Tag ìƒì„± ê·œì¹™ (Strict 3-Tier)
í†µê³„ ë¶„ì„ì„ ìœ„í•´ íƒœê·¸ëŠ” ë°˜ë“œì‹œ **`{Goal}_{Genre}_{Vibe}`** í˜•ì‹ì„ ì§€ì¼œì•¼ í•©ë‹ˆë‹¤.

- Prefix (Goal): ì‚¬ìš©ì ì…ë ¥ Goal ê·¸ëŒ€ë¡œ ì‚¬ìš©.
- Middle (Genre): ë°˜ë“œì‹œ ì•„ë˜ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ ì„ íƒ.
  - Options: [pop, k-pop, rock, hip-hop, r-nb, jazz, indie, folk, electronic, classical, ballad, acoustic, soundtrack, ambient, lo-fi, new-age, piano]
- Suffix (Vibe): ë¶„ìœ„ê¸°ë¥¼ ê°€ì¥ ì˜ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ 1ê°œ ì„ íƒ.
  - Options: [calm, groovy, intense, dreamy, uplifting, melancholy]

- Example: `focus_piano_calm`, `active_k-pop_uplifting`, `anger_rock_intense`

---

### 4. ì ˆëŒ€ì  ê·œì¹™ (CRITICAL RULES)
1. ì¶©ëŒ í•´ê²°(Conflict Resolution): ì‚¬ìš©ì ì„ í˜¸(Genre)ì™€ ìƒí™©(Context)ì´ ì¶©ëŒí•˜ë©´, ìƒí™©ì„ ìš°ì„ ì‹œí•˜ë˜ ì¥ë¥´ì˜ ëŠë‚Œë§Œ ìœ ì§€í•˜ì„¸ìš”. (ì˜ˆ: ë„ì„œê´€+ë©”íƒˆ â†’ ì–´ì¿ ìŠ¤í‹± ë©”íƒˆ/í¬ìŠ¤íŠ¸ ë½)
2. ê±°ì§“ë§ ê¸ˆì§€: ì‹¤ì œ Spotifyì— ì¡´ì¬í•˜ëŠ” ê³¡ë§Œ ì¶”ì²œí•˜ì„¸ìš”.
3. ì–¸ì–´ ë° í‚¤ì›Œë“œ ì„¤ì •: 
   - ì„¤ëª…(Reasoning)ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, í•µì‹¬ í‚¤ì›Œë“œ(Goal, Location, Genre, Vibe)ëŠ” ë°˜ë“œì‹œ ì˜ì–´ ì›ë¬¸ì„ ê´„í˜¸ `()` ì•ˆì— ë³‘ê¸°í•˜ì„¸ìš”.
   - Bad: "ë„ì„œê´€ì´ë¼ì„œ ì¡°ìš©í•œ í”¼ì•„ë…¸ ê³¡ì„ ê³¨ëìŠµë‹ˆë‹¤."
   - Good: "ì‚¬ìš©ìê°€ ë„ì„œê´€(Library)ì—ì„œ ì§‘ì¤‘(Focus)í•  ìˆ˜ ìˆë„ë¡, ì°¨ë¶„í•œ(Calm) ë¶„ìœ„ê¸°ì˜ í”¼ì•„ë…¸(Piano) ê³¡ì„ ì„ ì •í–ˆìŠµë‹ˆë‹¤."

---

### 5. ì¶œë ¥ í¬ë§· (JSON Schema)
ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON ë¦¬ìŠ¤íŠ¸ í¬ë§·ì´ì–´ì•¼ í•©ë‹ˆë‹¤. Markdown Block ì—†ì´ Raw Stringë§Œ ë°˜í™˜í•˜ì„¸ìš”.

[
  {
    "recommendation_meta": {
      "reasoning": "ì‚¬ìš©ìê°€ [ì¥ì†Œ(Location)]ì—ì„œ [ëª©í‘œ(Goal)]ë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆë„ë¡, [ì†ŒìŒ(Decibel)] í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ [ì¥ë¥´(Genre)]ë¥¼ ì„ ì •í–ˆìŠµë‹ˆë‹¤.",
      "primary_tag": "{Goal}_{Genre}_{Vibe}"
    },
    "track_info": {
      "artist_name": "Exact Artist Name",
      "track_title": "Exact Track Title"
    },
    "target_audio_features": {
      "min_tempo": (int),
      "max_tempo": (int),
      "target_energy": (float 0.0~1.0),
      "target_instrumentalness": (float 0.0~1.0),
      "target_valence": (float 0.0~1.0),
      "target_acousticness": (float 0.0~1.0)
    }
  }
]

### 6. í–‰ë™ ì§€ì¹¨ (Action Guideline)
- ì´ë¯¸ ê²€ìƒ‰(past_steps)ì„ 1íšŒ ì´ìƒ ìˆ˜í–‰í–ˆê³ , ìŒì•…ì„ ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ì¡°ê¸ˆì´ë¼ë„ ìˆë‹¤ë©´ **ì¦‰ì‹œ JSONì„ ìƒì„±í•˜ì—¬ 'response' í•„ë“œì— ë‹´ìœ¼ì‹­ì‹œì˜¤.**
- ì™„ë²½í•œ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ ë¬´ì˜ë¯¸í•œ ì¬ê²€ìƒ‰ì„ ë°˜ë³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- JSON ìƒì„±ì´ ê°€ëŠ¥í•˜ë‹¤ë©´ 'plan'ì„ ë¹„ìš°ê³  'response'ë§Œ ë°˜í™˜í•˜ì„¸ìš”.

### 7. ì…ë ¥ ì •ë³´
- Context: {user_context}
- Preference: {user_preference}
"""

replanner_prompt = ChatPromptTemplate.from_template(
    """{system_prompt}

    ì›ë˜ ëª©í‘œ: {input}

    í˜„ì¬ ê³„íš: {plan}

    ì™„ë£Œëœ ë‹¨ê³„ì™€ ê²°ê³¼:
    {past_steps}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì‹­ì‹œì˜¤:
    ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ 'response'ì— JSONì„ ì‘ì„±í•˜ê³ , ë¶€ì¡±í•˜ë©´ 'plan'ì„ ì‘ì„±í•˜ì„¸ìš”.
   """
)

edited_planner = replanner_prompt | llm.with_structured_output(Act)

# 5. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜

async def first_plan_step(state: PlanExecute):
    plan = await first_planner.ainvoke({
        "input": state["input"],
        "user_context": state["user_context"],
        "user_preference": state["user_preference"]
    })
    return {"plan": plan.steps}

async def execute_step(state: PlanExecute):
    plan = state["plan"]
    # ë‹¤ìŒ ì‹¤í–‰í•  ì‘ì—… (ì²« ë²ˆì§¸ ë‹¨ê³„)
    task = plan[0]

    # ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”
    task_formatted = f"""
    ì‚¬ìš©ì ì •ë³´: {state['user_context']}
    ì„ í˜¸ ì •ë³´: {state['user_preference']}

    ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ê²€ìƒ‰ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”: {task}
    """

    agent_response = await agent_executor.ainvoke(
        {"messages": [("user", task_formatted)]}
    )
    return {
        "past_steps": [(task, agent_response["messages"][-1].content)],
    }

async def edited_plan_step(state: PlanExecute):
    output = await edited_planner.ainvoke({
        "system_prompt": replanner_system_prompt,
        "input": state["input"],
        "plan": state["plan"],
        "past_steps": state["past_steps"],
        "user_context": str(state["user_context"]),
        "user_preference": str(state["user_preference"])
    })

    # response í•„ë“œê°€ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ì‘ë‹µ ë°˜í™˜
    if output.response:
        return {"response": output.response}
    # ì•„ë‹ˆë©´ plan ë°˜í™˜
    else:
        return {"plan": output.plan}

def should_end(state: PlanExecute):
    if "response" in state and state["response"]:
        return END
    else:
        return "agent"
    
# 6. ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(PlanExecute)

workflow.add_node("planner", first_plan_step)
workflow.add_node("agent", execute_step)
workflow.add_node("replan", edited_plan_step)

workflow.add_edge(START, "planner")
workflow.add_edge("planner", "agent")
workflow.add_edge("agent", "replan")

workflow.add_conditional_edges(
    "replan",
    should_end,
    ["agent", END],
)

######### ì™¸ë¶€(KPIí‰ê°€)ì—ì„œ import í•  ê°ì²´ (ì´ë¦„ì„ appìœ¼ë¡œ í†µì¼í•˜ë©´ í¸í•¨) #########
app = workflow.compile()

# =========================================================
# [add] KPI ì½”ë“œì™€ ì—°ê²°í•˜ê¸° ìœ„í•œ 'ë‹¤ë¦¬(Bridge)' í•¨ìˆ˜
# =========================================================
async def run_agent_bridge(inputs: dict):
    """
    KPI Evaluatorì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    inputs: dict í˜•íƒœë¡œ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    """
    # 1. ì…ë ¥ ë°ì´í„° êµ¬ì¡° ë³€í™˜ (Flat Dict -> Nested Dict)

    # 1. User Context ë§¤í•‘ (ê¸°ë³¸ê°’, ëŒ€ì†Œë¬¸ì ì²˜ë¦¬ í¬í•¨)
    user_context = {
        "location": str(inputs.get('location', 'home')).lower(), 
        "decibel_level": str(inputs.get('decibel', 'moderate')).lower(),
        "user_goal": str(inputs.get('goal', 'neutral')).lower(),
        "current_time": "14:00" 
    }

    # 2. User Preference ë§¤í•‘
    # (A) ì¥ë¥´ ì²˜ë¦¬
    # ê°’ì´ ì—†ê±°ë‚˜ ë¬¸ìì—´ 'None'ì´ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì·¨ê¸‰
    input_genre = inputs.get('user_pref') 
    genre_list = []
    if input_genre and input_genre != 'None':
        genre_list = [input_genre]

    # (B) ì•„í‹°ìŠ¤íŠ¸ ì²˜ë¦¬
    input_artist = inputs.get('user_artist')
    artist_list = []
    if input_artist and input_artist != 'None':
        # ë§Œì•½ ì…ë ¥ì´ "Artist1, Artist2" ì²˜ëŸ¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì²˜ë¦¬
        if isinstance(input_artist, list):
            artist_list = input_artist
        else:
            artist_list = [input_artist]

    user_preference = {
        "preferred_genres": genre_list,   # ì—†ìœ¼ë©´ [] (ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        "preferred_artists": artist_list  # ì—†ìœ¼ë©´ [] (ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    }
    
    # 2. ì´ˆê¸° State êµ¬ì„±
    initial_state = {
    "input": "Taxonomyì™€ Audio Features í¬ë§·ì„ ì¤€ìˆ˜í•˜ì—¬ ìŒì•… 3ê³¡ì„ ì¶”ì²œí•´ì¤˜.",
    "user_context": user_context,
    "user_preference": user_preference,
    "plan": [],
    "past_steps": []
    }
    
    # 3. ê·¸ë˜í”„ ì‹¤í–‰ 
    config = {"recursion_limit": 20}
    final_state = await app.ainvoke(initial_state, config=config)
    
    # 4. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_state.get('response', '{"error": "No response generated within limit"}')

# =========================================================
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê°•ë ¥í•´ì§„ íŒŒì‹± ê¸°ëŠ¥ íƒ‘ì¬)
# =========================================================
if __name__ == "__main__":
    import asyncio
    import json
    
    # í•µì‹¬ í•¨ìˆ˜: ë¬¸ìì—´ì—ì„œ JSON ë¶€ë¶„ë§Œ ì •ë°€í•˜ê²Œ íŒŒì‹±
    def extract_json_core(text):
        try:
            # 1. ë§ˆí¬ë‹¤ìš´ ì œê±°
            text = text.replace("```json", "").replace("```", "").strip()
            
            # 2. ë¦¬ìŠ¤íŠ¸('[')ì˜ ì‹œì‘ê³¼ ë(']') ìœ„ì¹˜ ì°¾ê¸°
            start_idx = text.find('[')
            end_idx = text.rfind(']')
            
            # ëŒ€ê´„í˜¸ê°€ ë‘˜ ë‹¤ ë°œê²¬ë˜ë©´ ê·¸ ì‚¬ì´ë§Œ ì˜ë¼ëƒ„
            if start_idx != -1 and end_idx != -1:
                return text[start_idx : end_idx + 1]
            
            # ëŒ€ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (í˜¹ì‹œ ê°ì²´ '{}'ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ)
            return text
        except Exception:
            return text

    async def main():
        print("ğŸ§ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì‹¤í–‰ ì¤‘...")

        test_inputs = {
            "location": "library",   
            "decibel": "silent",     
            "goal": "focus",         
            "user_pref": "Heavy Metal", #ì¶©ëŒì˜ˆì‹œ
            "user_artist": "Metallica" 
        }

        # 1. ê²°ê³¼ ë°›ê¸° (ì•„ì§ì€ ë¬¸ìì—´)
        raw_result = await run_agent_bridge(test_inputs)
        print(f"\n--- ì›ë³¸ ë¬¸ìì—´ ê¸¸ì´: {len(raw_result)} ---")

        # 2. íŒŒì‹± ì‹œë„
        try:
            clean_json_str = extract_json_core(raw_result)
            
            # ë³€í™˜ (String -> List/Dict)
            parsed_data = json.loads(clean_json_str)
            
            print("\nâœ… JSON íŒŒì‹± ì„±ê³µ!")
            print(json.dumps(parsed_data, indent=2, ensure_ascii=False))
            
            # í‚¤ í™•ì¸
            if isinstance(parsed_data, list) and len(parsed_data) > 0:
                print(f"\nğŸ”‘ í‚¤ í™•ì¸: {list(parsed_data[0].keys())}")
            
        except json.JSONDecodeError as e:
            print(f"\nâŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            print("ë¬¸ì œê°€ ëœ ë¶€ë¶„ ê·¼ì²˜:", clean_json_str[-50:]) # ëë¶€ë¶„ 50ìë§Œ í™•ì¸

    asyncio.run(main())