#pip install langgraph langchain langchain_openai langchain_google_genai tavily-python langchain_community "httpx==0.27.2"

import operator
import json
from typing import Annotated, List, Tuple, Union, Literal, Optional
from typing_extensions import TypedDict

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langgraph.prebuilt import create_react_agent
from langgraph.graph import StateGraph, END, START

import os
from dotenv import load_dotenv
import openai
from langchain_community.tools.tavily_search import TavilySearchResults #ë­ì²´ì¸ë„êµ¬


# 0. ì„¤ì • ë¡œë“œ # .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (KPI í‰ê°€ìš© ë“±)
openai_client = openai.Client(api_key=os.getenv("OPENAI_API_KEY"))

# 1. ë„êµ¬ ë° LLM ì„¤ì •

# Tavily ë„êµ¬ ì„¤ì • (API Key í™˜ê²½ë³€ìˆ˜ í™•ì¸)
# LangChain ë„êµ¬ë“¤ì€ ë³´í†µ os.environì— í‚¤ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì¸ì‹í•¨.
# ëª…ì‹œì ìœ¼ë¡œ í™•ì¸í•˜ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ì²˜ëŸ¼ ì‘ì„±.
if not os.getenv("TAVILY_API_KEY"):
    raise ValueError("Tavily API Keyê°€ ì—†ìŠµë‹ˆë‹¤!")

tavily_tool = TavilySearchResults(max_results=5)
tools = [tavily_tool]

# LLM ì„¤ì • ì¶”ì²œ ë¡œì§ì´ ë³µì¡í•˜ë¯€ë¡œ Plannerì™€ Replannerì—ëŠ” ê³ ì„±ëŠ¥ ëª¨ë¸(GPT-4o) ê¶Œì¥
llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)
# llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)

# Agent Executor ì„¤ì • #ê²€ìƒ‰ì„ ìˆ˜í–‰í•  ê°„ë‹¨í•œ Agent (íŠœí† ë¦¬ì–¼ì˜ execute_stepì—ì„œ ì‚¬ìš©)
agent_executor = create_react_agent(llm, tools)

# ---------------------------------------------------------
# 2. State ì •ì˜ (ì…ë ¥ ë°ì´í„°ë¥¼ ì €ì¥í•  êµ¬ì¡°)
# ---------------------------------------------------------
class PlanExecute(TypedDict):
    input: str                         # ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ (ë˜ëŠ” í¬ë§·íŒ…ëœ ë¬¸ìì—´)
    user_context: dict                 # location, decibel_level, user_goal, current_time
    user_preference: dict              # preferred_genres, preferred_artists
    plan: List[str]                    # ì‹¤í–‰ ê³„íš
    past_steps: Annotated[List[Tuple], operator.add] # ìˆ˜í–‰í•œ ì‘ì—… ê¸°ë¡
    response: str                      # ìµœì¢… JSON ì‘ë‹µ

# 3. ë°ì´í„° ëª¨ë¸ (Pydantic) ì •ì˜
class Plan(BaseModel):
    """ê²€ìƒ‰ ê³„íš"""
    steps: List[str] = Field(description="ê²€ìƒ‰ ë‹¨ê³„")

# class Response(BaseModel):
#     """ìµœì¢… ì‚¬ìš©ì ì‘ë‹µ"""
#     response: str = Field(description="ìµœì¢… ì¶”ì²œ ê²°ê³¼ (ë°˜ë“œì‹œ JSON í˜•ì‹ì„ ë”°ë¥¼ ê²ƒ)")

class Act(BaseModel):
    """
    Replannerì˜ íŒë‹¨ ê²°ê³¼:
    - ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ response í•„ë“œì— ìµœì¢… JSONì„ ë‹´ìŒ
    - ë¶€ì¡±í•˜ë©´ plan í•„ë“œì— ì¶”ê°€ ê³„íšì„ ë‹´ìŒ
    responseì™€ plan ì¤‘ í•˜ë‚˜ëŠ” ë°˜ë“œì‹œ ì±„ì›Œì ¸ì•¼ í•¨
    """

    # Response classë‘ ê²¹ì¹¨
    response: Optional[str] = Field(
        default=None,
        description="ìµœì¢… JSON ì‘ë‹µ (ì •ë³´ê°€ ì¶©ë¶„í•  ë•Œ ì‘ì„±í•˜ëŠ” í•„ë“œ)"
    )
    plan: Optional[List[str]] = Field(
        default=None,
        description="ì¶”ê°€ ê³„íš (ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì‘ì„±í•˜ëŠ” í•„ë“œ)"
    )

# ---------------------------------------------------------
# 4. Prompts ì„¤ì • (Taxonomy & Output Format ë°˜ì˜)
# ---------------------------------------------------------

# (1) ì´ˆê¸° ê³„íš ìˆ˜ë¦½ í”„ë¡¬í”„íŠ¸
planner_prompt = ChatPromptTemplate.from_messages([
    ("system",
     """ë‹¹ì‹ ì€ ìŒì•… ì¶”ì²œì„ ìœ„í•œ ê²€ìƒ‰ ê³„íšê°€ì…ë‹ˆë‹¤.
     ì‚¬ìš©ìì˜ Contextì™€ Preferenceë¥¼ ë¶„ì„í•˜ì—¬ Tavilyë¡œ ê²€ìƒ‰í•  ë‹¨ê³„ë³„ ê³„íšì„ ì„¸ìš°ì„¸ìš”.
     
     [Taxonomy ì°¸ê³ ]
     - Location: cafe, library, co-working, moving, gym, home, park
     - Goal: focus, relax, sleep, active, anger, consolation, neutral
     """),
    ("user", "Context: {user_context}\nPreference: {user_preference}\nRequest: {input}")
])

first_planner = planner_prompt | llm.with_structured_output(Plan)

# (2) Replanner (ê²€í†  ë° ë‹µë³€ ìƒì„±) í”„ë¡¬í”„íŠ¸ - *ì—¬ê¸°ì— ì‘ì„±í•˜ì‹  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ í•µì‹¬ ë¡œì§ìœ¼ë¡œ ë„£ìŠµë‹ˆë‹¤*
replanner_system_prompt = replanner_system_prompt = """
ë‹¹ì‹ ì€ 'ìƒí™© ë§¥ë½ ì¸ì‹ ìŒì•… ì¶”ì²œ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ [Taxonomy]ì— ìµœì í™”ëœ ìŒì•…ì„ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

### 1. Taxonomy Definition (ì—„ìˆ˜)
- **Location**:
  - `library`, `co-working`: ê°€ì‚¬ ì—†ëŠ” ì—°ì£¼ê³¡(Instrumental) ë˜ëŠ” ë°±ìƒ‰ì†ŒìŒ ìœ„ì£¼ (ì§‘ì¤‘ë ¥ ë°©í•´ ê¸ˆì§€).
  - `gym`, `moving`, `active`: BPMì´ ë¹ ë¥´ê³  ë¦¬ë“¬ê°ì´ í™•ì‹¤í•œ ê³¡.
  - `sleep`: ê¸‰ê²©í•œ ë³€í™”ê°€ ì—†ê³ , ë§¤ìš° ì°¨ë¶„í•œ ê³¡.
- **Goal**:
  - `anger`: ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ í•´ì†Œí•  ê°•ë ¬í•œ ê³¡(Vent) ë˜ëŠ” ì§„ì •ì„ ìœ„í•œ ì°¨ë¶„í•œ ê³¡(Calm).
  - `focus`: ë°˜ë³µì ì´ê³  ë‹¨ìˆœí•œ ë¹„íŠ¸(Lo-fi, Jazz, Classical).
  - `consolation`: ë”°ëœ»í•œ ë©œë¡œë””ì™€ ì„œì •ì ì¸ ê°€ì‚¬.
- **Decibel**:
  - `silent`, `quiet`: ì¡°ìš©í•œ í™˜ê²½ì„ ê¹¨ì§€ ì•Šë„ë¡ Energy/Loudness ë‚®ê²Œ ì„¤ì •.
  - `very_loud`: ì†ŒìŒì„ ë®ì„ ìˆ˜ ìˆë„ë¡(Masking) ì‚¬ìš´ë“œê°€ ê½‰ ì°¬ ê³¡ ì¶”ì²œ.

### 2. Audio Features ì¶”ë¡  ê°€ì´ë“œ (0.0 ~ 1.0)
JSONì˜ `target_audio_features` ê°’ì„ ì±„ìš¸ ë•Œ ì•„ë˜ ë²”ìœ„ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.
- **Focus/Sleep**:
  - Energy: 0.0 ~ 0.4 (ë‚®ìŒ)
  - Tempo: 60 ~ 90 BPM (ëŠë¦¼)
  - Instrumentalness: 0.7 ~ 1.0 (ê°€ì‚¬ ê±°ì˜ ì—†ìŒ)
- **Active/Anger(Vent)**:
  - Energy: 0.7 ~ 1.0 (ë†’ìŒ)
  - Tempo: 120+ BPM (ë¹ ë¦„)
  - Valence: 0.6+ (ê¸ì •ì /ê°•ë ¬í•¨)
- **Relax/Consolation**:
  - Acousticness: 0.6 ~ 1.0 (ìì—° ì•…ê¸°)
  - Valence: 0.3 ~ 0.6 (ì°¨ë¶„í•¨)

### 3. ì ˆëŒ€ì  ê·œì¹™ (CRITICAL RULES)
1. **ì·¨í–¥ ê¸°ë°˜ í•„í„°ë§(Priority)**: ë¬´ì‘ìœ„ ì¶”ì²œì„ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë°˜ë“œì‹œ `{user_preference}`ì— ìˆëŠ” ì„ í˜¸ ì¥ë¥´/ì•„í‹°ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ ìŠ¤íƒ€ì¼ ë‚´ì—ì„œ, í˜„ì¬ Contextì— ì í•©í•œ ê³¡ì„ ì°¾ìœ¼ì„¸ìš”.
2. **ê±°ì§“ë§ ê¸ˆì§€**: ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ë¦¬ë¯¹ìŠ¤ë‚˜ ì»¤ë²„ê³¡ì„ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
3. **ì¶©ëŒ í•´ê²°(Conflict Resolution)**: ì‚¬ìš©ìì˜ ì„ í˜¸ ì¥ë¥´ê°€ ìƒí™©(Context)ê³¼ ë§ì§€ ì•Šì„ ê²½ìš°, ìƒí™©ì„ ìš°ì„ ì‹œí•˜ë˜ ì¥ë¥´ì˜ ëŠë‚Œ(Vibe)ì€ ìœ ì§€í•˜ì„¸ìš”. (ì˜ˆ: ë„ì„œê´€ì—ì„œ ë©”íƒˆ -> ì–´ì¿ ìŠ¤í‹± ë©”íƒˆ/í¬ìŠ¤íŠ¸ ë½ ì¶”ì²œ)
4. **ìŠ¤í¬í‹°íŒŒì´ í˜¸í™˜**: ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì— ì¡´ì¬í•˜ëŠ” ê³¡ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
5. **ìµœì‹  íŠ¸ë Œë“œ**: ê°€ëŠ¥í•˜ë‹¤ë©´ ì‚¬ìš©ì ìš”ì²­ ë‚ ì§œ ê¸°ì¤€ ìµœê·¼ 1ë…„ ë‚´ ë°œë§¤ê³¡ì„ 1ê³¡ ì´ìƒ í¬í•¨í•˜ì„¸ìš”.
6. **í¬ë§· ì—„ìˆ˜**: Markdown Block(```json)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ **Raw JSON String**ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

### 4. ì¶œë ¥ í¬ë§· (JSON Schema)
ë°˜ë“œì‹œ ì•„ë˜ì˜ **JSON ë¦¬ìŠ¤íŠ¸** í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[
  {
    "recommendation_meta": {
      "reasoning": "ë„ì„œê´€(Library) í™˜ê²½ì´ë¯€ë¡œ ì‚¬ìš©ìê°€ ì„ í˜¸í•˜ëŠ” ë½ ì¥ë¥´ ì¤‘ ê°€ì‚¬ê°€ ì—†ê³  ì°¨ë¶„í•œ í¬ìŠ¤íŠ¸ ë½ì„ ì„ ì •í–ˆìŠµë‹ˆë‹¤.", 
      "primary_tag": "focus_instrumental" 
    },
    "track_info": {
      "artist_name": "Artist Name",
      "track_title": "Track Title"
    },
    "target_audio_features": {
      "min_tempo": 80, 
      "max_tempo": 100,
      "target_energy": 0.4,       
      "target_instrumentalness": 0.9, 
      "target_valence": 0.6,      
      "target_acousticness": 0.4  
    }
  }
]

### 5. ì…ë ¥ ì •ë³´
- Context: {user_context}
- Preference: {user_preference}
"""

replanner_prompt = ChatPromptTemplate.from_template(
    """{system_prompt}

    ì›ë˜ ëª©í‘œ: {input}

    í˜„ì¬ ê³„íš: {plan}

    ì™„ë£Œëœ ë‹¨ê³„ì™€ ê²°ê³¼:
    {past_steps}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì‹­ì‹œì˜¤:
    ì •ë³´ê°€ ì¶©ë¶„í•˜ë©´ 'response'ì— JSONì„ ì‘ì„±í•˜ê³ , ë¶€ì¡±í•˜ë©´ 'plan'ì„ ì‘ì„±í•˜ì„¸ìš”.
   """
)

edited_planner = replanner_prompt | llm.with_structured_output(Act)

# 5. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜

async def first_plan_step(state: PlanExecute):
    plan = await first_planner.ainvoke({
        "input": state["input"],
        "user_context": state["user_context"],
        "user_preference": state["user_preference"]
    })
    return {"plan": plan.steps}

async def execute_step(state: PlanExecute):
    plan = state["plan"]
    # ë‹¤ìŒ ì‹¤í–‰í•  ì‘ì—… (ì²« ë²ˆì§¸ ë‹¨ê³„)
    task = plan[0]

    # ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™”
    task_formatted = f"""
    ì‚¬ìš©ì ì •ë³´: {state['user_context']}
    ì„ í˜¸ ì •ë³´: {state['user_preference']}

    ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ê²€ìƒ‰ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì„¸ìš”: {task}
    """

    agent_response = await agent_executor.ainvoke(
        {"messages": [("user", task_formatted)]}
    )
    return {
        "past_steps": [(task, agent_response["messages"][-1].content)],
    }

async def edited_plan_step(state: PlanExecute):
    output = await edited_planner.ainvoke({
        "system_prompt": replanner_system_prompt,
        "input": state["input"],
        "plan": state["plan"],
        "past_steps": state["past_steps"],
        "user_context": str(state["user_context"]),
        "user_preference": str(state["user_preference"])
    })

    # response í•„ë“œê°€ ì±„ì›Œì ¸ ìˆìœ¼ë©´ ì‘ë‹µ ë°˜í™˜
    if output.response:
        return {"response": output.response}
    # ì•„ë‹ˆë©´ plan ë°˜í™˜
    else:
        return {"plan": output.plan}

def should_end(state: PlanExecute):
    if "response" in state and state["response"]:
        return END
    else:
        return "agent"
    
# 6. ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(PlanExecute)

workflow.add_node("planner", first_plan_step)
workflow.add_node("agent", execute_step)
workflow.add_node("replan", edited_plan_step)

workflow.add_edge(START, "planner")
workflow.add_edge("planner", "agent")
workflow.add_edge("agent", "replan")

workflow.add_conditional_edges(
    "replan",
    should_end,
    ["agent", END],
)

######### ì™¸ë¶€(KPIí‰ê°€)ì—ì„œ import í•  ê°ì²´ (ì´ë¦„ì„ appìœ¼ë¡œ í†µì¼í•˜ë©´ í¸í•¨) #########
app = workflow.compile()

# =========================================================
# [add] KPI ì½”ë“œì™€ ì—°ê²°í•˜ê¸° ìœ„í•œ Bridge í•¨ìˆ˜
# =========================================================
async def run_agent_bridge(inputs: dict):
    """
    KPI Evaluatorì—ì„œ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    inputs: dict í˜•íƒœë¡œ ì…ë ¥ ë°ì´í„°ë¥¼ ë°›ìŠµë‹ˆë‹¤.
    """
    # 1. ì…ë ¥ ë°ì´í„° êµ¬ì¡° ë³€í™˜ (Flat Dict -> Nested Dict)

    # 1. User Context ë§¤í•‘ (ê¸°ë³¸ê°’, ëŒ€ì†Œë¬¸ì ì²˜ë¦¬ í¬í•¨)
    user_context = {
        "location": str(inputs.get('location', 'home')).lower(), 
        "decibel_level": str(inputs.get('decibel', 'moderate')).lower(),
        "user_goal": str(inputs.get('goal', 'neutral')).lower(),
        "current_time": "14:00" 
    }

    # 2. User Preference ë§¤í•‘
    # (A) ì¥ë¥´ ì²˜ë¦¬
    # ê°’ì´ ì—†ê±°ë‚˜ ë¬¸ìì—´ 'None'ì´ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì·¨ê¸‰
    input_genre = inputs.get('user_pref') 
    genre_list = []
    if input_genre and input_genre != 'None':
        genre_list = [input_genre]

    # (B) ì•„í‹°ìŠ¤íŠ¸ ì²˜ë¦¬
    input_artist = inputs.get('user_artist')
    artist_list = []
    if input_artist and input_artist != 'None':
        # ë§Œì•½ ì…ë ¥ì´ "Artist1, Artist2" ì²˜ëŸ¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì²˜ë¦¬
        if isinstance(input_artist, list):
            artist_list = input_artist
        else:
            artist_list = [input_artist]

    user_preference = {
        "preferred_genres": genre_list,   # ì—†ìœ¼ë©´ [] (ë¹ˆ ë¦¬ìŠ¤íŠ¸)
        "preferred_artists": artist_list  # ì—†ìœ¼ë©´ [] (ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    }
    
    # 2. ì´ˆê¸° State êµ¬ì„±
    initial_state = {
    "input": "Taxonomyì™€ Audio Features í¬ë§·ì„ ì¤€ìˆ˜í•˜ì—¬ ìŒì•… 3ê³¡ì„ ì¶”ì²œí•´ì¤˜.",
    "user_context": user_context,
    "user_preference": user_preference,
    "plan": [],
    "past_steps": []
    }
    
    # 3. ê·¸ë˜í”„ ì‹¤í–‰ 
    config = {"recursion_limit": 20}
    final_state = await app.ainvoke(initial_state, config=config)
    
    # 4. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return final_state.get('response', '{"error": "No response generated within limit"}')

# =========================================================
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê°•ë ¥í•´ì§„ íŒŒì‹± ê¸°ëŠ¥ íƒ‘ì¬)
# =========================================================
if __name__ == "__main__":
    import asyncio
    import json
    
    # í•µì‹¬ í•¨ìˆ˜: ë¬¸ìì—´ì—ì„œ JSON ë¶€ë¶„ë§Œ ì •ë°€í•˜ê²Œ íŒŒì‹±
    def extract_json_core(text):
        try:
            # 1. ë§ˆí¬ë‹¤ìš´ ì œê±°
            text = text.replace("```json", "").replace("```", "").strip()
            
            # 2. ë¦¬ìŠ¤íŠ¸('[')ì˜ ì‹œì‘ê³¼ ë(']') ìœ„ì¹˜ ì°¾ê¸°
            start_idx = text.find('[')
            end_idx = text.rfind(']')
            
            # ëŒ€ê´„í˜¸ê°€ ë‘˜ ë‹¤ ë°œê²¬ë˜ë©´ ê·¸ ì‚¬ì´ë§Œ ì˜ë¼ëƒ„
            if start_idx != -1 and end_idx != -1:
                return text[start_idx : end_idx + 1]
            
            # ëŒ€ê´„í˜¸ê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (í˜¹ì‹œ ê°ì²´ '{}'ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ)
            return text
        except Exception:
            return text

    async def main():
        print("ğŸ§ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ì‹¤í–‰ ì¤‘...")

        test_inputs = {
            "location": "library",   
            "decibel": "silent",     
            "goal": "focus",         
            "user_pref": "Heavy Metal", #ì¶©ëŒì˜ˆì‹œ
            "user_artist": "Metallica" 
        }

        # 1. ê²°ê³¼ ë°›ê¸° (ì•„ì§ì€ ë¬¸ìì—´)
        raw_result = await run_agent_bridge(test_inputs)
        print(f"\n--- ì›ë³¸ ë¬¸ìì—´ ê¸¸ì´: {len(raw_result)} ---")

        # 2. íŒŒì‹± ì‹œë„
        try:
            # ì •ë°€ ì¶”ì¶œ
            clean_json_str = extract_json_core(raw_result)
            
            # ë³€í™˜ (String -> List/Dict)
            parsed_data = json.loads(clean_json_str)
            
            print("\nâœ… JSON íŒŒì‹± ì„±ê³µ!")
            print(json.dumps(parsed_data, indent=2, ensure_ascii=False))
            
            # í‚¤ í™•ì¸
            if isinstance(parsed_data, list) and len(parsed_data) > 0:
                print(f"\nğŸ”‘ í‚¤ í™•ì¸: {list(parsed_data[0].keys())}")
            
        except json.JSONDecodeError as e:
            print(f"\nâŒ JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            print("ë¬¸ì œê°€ ëœ ë¶€ë¶„ ê·¼ì²˜:", clean_json_str[-50:]) # ëë¶€ë¶„ 50ìë§Œ í™•ì¸

    asyncio.run(main())